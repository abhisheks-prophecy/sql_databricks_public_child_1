{
  "id" : "uitesting_replacewhere",
  "metainfo" : {
    "label" : "uitesting_replacewhere",
    "autoLayout" : false,
    "staleState" : "none",
    "sourceSuggestions" : {
      "sources" : [ ]
    },
    "graphConfig" : {
      "entityConfig" : {
        "incremental_predicates" : [ "\"c_tinyint > -1\nAND c_int <= 10000\nAND (\n      c_struct.city IS NOT NULL\n      AND c_struct.pin IS NOT NULL\n      AND date_add('2020-01-02', c_tinyint) IS NOT NULL\n      AND concat(\n            c_array[0], \n            c_struct.city, \n            aes_decrypt(unhex('83F16B2AA704794132802D248E6BFD4E380078182D1544813898AC97E709B28A94'), '0000111122223333'), \n            base64(aes_encrypt('Spark SQL', '1234567890abcdef', 'ECB', 'PKCS')), \n            bin(13), \n            btrim('    SparkSQL   '), \n            char(65), \n            chr(65), \n            concat('Spark', 'SQL'), \n            concat_ws(' ', 'Spark', 'SQL'), \n            crc32('Spark'), \n            current_catalog(), \n            current_database(), \n            current_date(), \n            current_timestamp(), \n            current_timezone(), \n            current_user(), \n            date_add('2016-07-30', 1), \n            date_sub('2016-07-30', 1), \n            date_format('2016-04-08', 'y'), \n            date_from_unix_date(1), \n            date_part('YEAR', TIMESTAMP'2019-08-12 01:00:00.123456'), \n            date_part('MONTH', INTERVAL '2021-11' YEAR TO MONTH), \n            date_part('MINUTE', INTERVAL '123 23:55:59.002001' DAY TO SECOND), \n            date_trunc('HOUR', '2015-03-05T09:32:05.359'), \n            date_trunc('DD', '2015-03-05T09:32:05.359'), \n            datediff('2009-07-31', '2009-07-30'), \n            decode(encode('abc', 'utf-8'), 'utf-8'), \n            e(), \n            elt(1, 'scala', 'java'), \n            format_number(12332.123456, '##################.###'), \n            format_string('Hello World %d %s', 100, 'days'), \n            CAST(from_csv('1, 0.8', 'a INT, b DOUBLE') AS string), \n            CAST(from_json(\n              '{\\\"teacher\\\": \\\"Alice\\\", \\\"student\\\": [{\\\"name\\\": \\\"Bob\\\", \\\"rank\\\": 1}, {\\\"name\\\": \\\"Charlie\\\", \\\"rank\\\": 2}]}', \n              'STRUCT<teacher: STRING, student: ARRAY<STRUCT<name: STRING, rank: INT>>>') AS string), \n            CAST(from_unixtime(0, 'yyyy-MM-dd HH:mm:ss') AS string), \n            CAST(from_utc_timestamp('2016-08-31', 'Asia/Seoul') AS string), \n            CAST(get_json_object('{\\\"a\\\":\\\"b\\\"}', '$.a') AS string), \n            hash('Spark', array(123), 2), \n            hex(17), \n            CAST(hour('2009-07-30 12:58:59') AS string), \n            CAST(hypot(3, 4) AS string), \n            CAST(ilike('Spark', '_Park') AS string), \n            CAST(initcap('sPark sql') AS string), \n            CAST(last_day('2009-01-12') AS string), \n            CAST(lcase('SparkSql') AS string), \n            CAST(if(\n              1 < 2, \n              'a', \n              'b') AS string), \n            LEFT('Spark SQL', 3), \n            lower('SparkSql'), \n            lpad('hi', 5, '??'), \n            ltrim('    SparkSQL   '), \n            CAST(make_date(2013, 7, 15) AS string), \n            CAST(make_dt_interval(1, 12, 30, 1.001001) AS string), \n            CAST(make_interval(100, 11, 1, 1, 12, 30, 1.001001) AS string), \n            CAST(make_timestamp(2019, 6, 30, 23, 59, 60) AS string), \n            CAST(make_ym_interval(1, 2) AS string), \n            md5('Spark'), \n            next_day('2015-01-14', 'TU'), \n            now(), \n            nullif(2, 2), \n            CAST(overlay('Spark SQL' PLACING '_' FROM 6) AS string), \n            CAST(parse_url('http://spark.apache.org/path?query=1', 'HOST') AS string), \n            printf('Hello World %d %s', 100, 'days'), \n            CAST(regexp_extract('100-200', '(\\\\d+)-(\\\\d+)', 1) AS string), \n            CAST(regexp_replace('100-200', '(\\\\d+)', 'num') AS string), \n            repeat('123', 2), \n            replace('ABCabc', 'abc', 'DEF'), \n            reverse('Spark SQL'), \n            RIGHT('Spark SQL', 3), \n            rpad('hi', 5, '??'), \n            rtrim('    SparkSQL   '), \n            CAST(schema_of_json('[{\\\"col\\\":0}]') AS string), \n            sha('Spark'), \n            sha1('Spark'), \n            sha2('Spark', 256), \n            concat(space(2), '1'), \n            split_part('11.12.13', '.', 3), \n            substr('Spark SQL', 5), \n            substring('Spark SQL', 5), \n            substring_index('www.apache.org', '.', 2), \n            timestamp_micros(1230219000123123), \n            timestamp_millis(1230219000123), \n            timestamp_seconds(1.230219000123E9), \n            to_csv(named_struct('a', 1, 'b', 2)), \n            to_date('2009-07-30 04:17:52'), \n            to_timestamp('2016-12-31 00:12:00'), \n            to_unix_timestamp('2016-04-08', 'yyyy-MM-dd'), \n            to_utc_timestamp('2016-08-31', 'Asia/Seoul'), \n            translate('AaBbCc', 'abc', '123'), \n            trunc('2019-08-04', 'week'), \n            try_to_binary('abc', 'utf-8'), \n            try_to_number('454', '999'), \n            typeof(1), \n            ucase('SparkSql'), \n            unbase64('U3BhcmsgU1FM'), \n            decode(unhex('537061726B2053514C'), 'UTF-8'), \n            unix_date(DATE(\\\"1970-01-02\\\")), \n            unix_micros(TIMESTAMP('1970-01-01 00:00:01Z')), \n            unix_millis(TIMESTAMP('1970-01-01 00:00:01Z')), \n            unix_seconds(TIMESTAMP('1970-01-01 00:00:01Z')), \n            unix_timestamp('2016-04-08', 'yyyy-MM-dd'), \n            upper('SparkSql'), \n            uuid(), \n            xpath_string('<a><b>b</b><c>cc</c></a>', 'a/c'), \n            xxhash64('Spark', array(123), 2), \n            YEAR ('2016-07-30'), \n            to_json(array(named_struct('a', 1, 'b', 2)))) IS NOT NULL\n      AND (2 % 1.8)\n          + '20'::INTEGER\n          + (MOD(2, 1.8))\n          + (3 & 5)\n          + (2 * 3)\n          + (5 + 10)\n          - (100 + 45)\n          + (3 / 2)\n          + (3 ^ 5)\n          + abs(-1)\n          + acos(1)\n          + acosh(1)\n          + array_position(array(3, 2, 1), 1)\n          + array_size(array('b', 'd', 'c', 'a'))\n          + ascii(2)\n          + asin(0)\n          + asinh(0)\n          + atan(0)\n          + atan2(0, 0)\n          + atanh(0)\n          + bit_count(0)\n          + bit_get(11, 0)\n          + bit_length('Spark SQL')\n          + bround(25, -1)\n          + cardinality(array('b', 'd', 'c', 'a'))\n          + cardinality(map('a', 1, 'b', 2))\n          + CAST('10' AS int)\n          + cbrt(27.0)\n          + ceil(3.1411, 3)\n          + ceiling(3.1411, 3)\n          + char_length('Spark SQL ')\n          + conv('100', 2, 10)\n          + cos(0)\n          + cosh(0)\n          + cot(1)\n          + csc(1)\n          + day('2009-07-30')\n          + dayofmonth('2009-07-30')\n          + dayofweek('2009-07-30')\n          + dayofyear('2016-04-09')\n          + degrees(3.141592653589793)\n          + element_at(array(1, 2, 3), 2)\n          + exp(0)\n          + expm1(0)\n          + EXTRACT(SECONDS FROM TIMESTAMP'2019-10-01 00:00:01.000001')\n          + EXTRACT(MINUTE FROM INTERVAL '123 23:55:59.002001' DAY TO SECOND)\n          + factorial(2)\n          + find_in_set('ab', 'abc,b,ab,c,def')\n          + floor(-0.1)\n          + getbit(11, 0)\n          + greatest(10, 9, 2, 4, 3)\n          + instr('SparkSQL', 'SQL')\n          + json_array_length('[1,2,3,{\\\"f1\\\":1,\\\"f2\\\":[5,6]},4]')\n          + least(10, 9, 2, 4, 3)\n          + length('Spark SQL ')\n          + levenshtein('kitten', 'sitting')\n          + ln(10)\n          + locate('bar', 'foobarbar')\n          + log(10, 100)\n          + log10(10)\n          + log1p(0)\n          + log2(2)\n          + minute('2009-07-30 12:58:59')\n          + (2 % 1.8)\n          + month('2016-07-30')\n          + months_between('1997-02-28 10:30:00', '1996-10-30', false)\n          + nanvl(CAST('NaN' AS double), 123)\n          + negative(100)\n          + octet_length('Spark SQL')\n          + pi()\n          + pmod(10, 3)\n          + position('bar', 'foobarbar')\n          + positive(1)\n          + pow(2, 3)\n          + power(2, 3)\n          + quarter('2016-08-31')\n          + radians(180)\n          + rand()\n          + randn()\n          + random()\n          + rint(12.3456)\n          + round(2.5, 0)\n          + sec(0)\n          + second('2009-07-30 12:58:59')\n          + shiftleft(2, 1)\n          + shiftright(4, 1)\n          + shiftrightunsigned(4, 1)\n          + sign(40)\n          + signum(40)\n          + sin(0)\n          + sinh(0)\n          + size(array('b', 'd', 'c', 'a'))\n          + sqrt(4)\n          + tan(0)\n          + tanh(0)\n          + to_number('454.00', '000.00')\n          + try_add(1, 2)\n          + try_divide(2L, 2L)\n          + try_element_at(array(1, 2, 3), 2)\n          + try_multiply(2, 3)\n          + try_subtract(2, 1)\n          + weekday('2009-07-30')\n          + weekofyear('2008-02-20')\n          + (\n              CASE\n                WHEN 1 > 0\n                  THEN 1\n                WHEN 2 > 0\n                  THEN 2.0\n                ELSE 1.2\n              END\n            )\n          + width_bucket(5.3, 0.2, 10.6, 5)\n          + xpath_double('<a><b>1</b><b>2</b></a>', 'sum(a/b)')\n          + xpath_int('<a><b>1</b><b>2</b></a>', 'sum(a/b)')\n          + xpath_long('<a><b>1</b><b>2</b></a>', 'sum(a/b)')\n          + xpath_number('<a><b>1</b><b>2</b></a>', 'sum(a/b)')\n          + xpath_short('<a><b>1</b><b>2</b></a>', 'sum(a/b)')\n          + (~ 0) != 2\n      AND CASE\n            WHEN (1 != 2)\n            or (1 < 2)\n            or (2 <= 2)\n            or (2 <=> 2)\n            or ((2 % 1.8) == 1)\n            or (to_date('2009-07-30 04:17:52') < to_date('2009-07-30 04:17:52'))\n            or (add_months('2016-08-31', 1) < add_months('2017-08-31', 3))\n            or (true and false)\n            or array_contains(array_distinct(array(1, 2, 3)), 2)\n            or array_contains(array_except(array(1, 2, 3), array(1, 3, 5)), 2)\n            or array_contains(array_intersect(array(1, 2, 3), array(1, 3, 5)), 10)\n            or (array_join(array('hello', 'world'), ' ', ',') LIKE '%hello%')\n            or (array_max(array(1, 20, 3)) > 10)\n            or (array_min(array(1, 20, 3)) > 20)\n            or array_contains(array_remove(array(1, 2, 3, 3), 3), 3)\n            or array_contains(array_repeat(5, 2), 6)\n            or array_contains(array_union(array(1, 2, 3), array(1, 3, 5)), 10)\n            or arrays_overlap(array(1, 2, 3), array(3, 4, 5))\n            or (10 BETWEEN 2 AND 20)\n            or contains('Spark SQL', 'Spark')\n            or endswith('Spark SQL', 'SQL')\n            or (\n                 EXISTS(\n                   array(1, 2, 3), \n                   x -> x % 2 == 0)\n               )\n            or array_contains(filter(\n                 array(1, 2, 3), \n                 x -> x % 2 == 1), 5)\n            or array_contains(flatten(array(array(1, 2), array(3, 4))), 10)\n            or forall(\n                 array(1, 2, 3), \n                 x -> x % 2 == 0)\n            or ilike('Spark', '_Park')\n            or (1 IN (2, 3, 4))\n            or (isnan(CAST('NaN' AS double)))\n            or isnotnull(1)\n            or isnull(1)\n            or array_contains(json_object_keys('{\\\"key\\\": \\\"value\\\"}'), 'key1')\n            or like('Spark', '_park')\n            or map_contains_key(map(1, 'a', 2, 'b'), 1)\n            or map_contains_key(map_concat(map(1, 'a', 2, 'b'), map(3, 'c')), 4)\n            or map_contains_key(map_filter(\n                 map(1, 0, 2, 2, 3, -1), \n                 (k, v) -> k > v), 3)\n            or map_contains_key(map_from_arrays(array(1.0, 3.0), array('2', '4')), 2)\n            or map_contains_key(map_from_entries(array(struct(1, 'a'), struct(2, 'b'))), 1)\n            or array_contains(map_keys(map(1, 'a', 2, 'b')), 2)\n            or array_contains(map_values(map(1, 'a', 2, 'b')), 'a')\n            or map_contains_key(map_zip_with(\n                 map(1, 'a', 2, 'b'), \n                 map(1, 'x', 2, 'y'), \n                 (k, v1, v2) -> concat(v1, v2)), 1)\n            or (named_struct('a', 1, 'b', 2) IN (named_struct('a', 1, 'b', 1), named_struct('a', 1, 'b', 3)))\n            or (NOT true)\n            or array_contains(regexp_extract_all('100-200, 300-400', '(\\\\d+)-(\\\\d+)', 1), '100')\n            or array_contains(sequence(1, 5), 4)\n            or array_contains(shuffle(array(1, 20, 3, 5)), 10)\n            or array_contains(slice(array(1, 2, 3, 4), 2, 2), 4)\n            or array_contains(sort_array(array('b', 'd', 'c', 'a'), true), 'b')\n            or array_contains(split('oneAtwoBthreeC', '[ABC]'), 'one')\n            or startswith('Spark SQL', 'Spark')\n            or map_contains_key(str_to_map('a:1,b:2,c:3', ',', ':'), 'a')\n            or array_contains(transform(\n                 array(1, 2, 3), \n                 x -> x + 1), 1)\n            or map_contains_key(transform_keys(\n                 map_from_arrays(array(1, 2, 3), array(1, 2, 3)), \n                 (k, v) -> k + 1), 1)\n            or map_contains_key(transform_values(\n                 map_from_arrays(array(1, 2, 3), array(1, 2, 3)), \n                 (k, v) -> v + 1), 2)\n            or array_contains(xpath('<a><b>b1</b><b>b2</b><b>b3</b><c>c1</c><c>c2</c></a>', 'a/b/text()'), 'a')\n            or xpath_boolean('<a><b>1</b></a>', 'a/b')\n            or array_contains(zip_with(\n                 array(1, 2), \n                 array(3, 4), \n                 (x, y) -> x + y), 1) = true\n              THEN true\n            ELSE false\n          END\n    )\"" ],
        "alias" : "\"alias_uitesting_replacewhere\"",
        "materialized" : "incremental",
        "on_schema_change" : "'append_new_columns'",
        "incremental_strategy" : "'replace_where'",
        "type" : "ModelConfig"
      }
    },
    "version" : 3
  },
  "processes" : {
    "uitesting_replacewhere##wceiJ6rJ" : {
      "id" : "uitesting_replacewhere##wceiJ6rJ",
      "component" : "TargetModel",
      "metadata" : {
        "label" : "uitesting_replacewhere",
        "x" : 300,
        "y" : 20,
        "phase" : 0,
        "macroDependencies" : [ ],
        "comment" : "Retrieves all records from a dataset with various column types for testing purposes.",
        "autoUpdateComment" : true
      },
      "properties" : {
        "customQueryDisabled" : true,
        "customQuery" : false,
        "incrementalEditorDisabled" : true,
        "query" : "SELECT * \n\nFROM all_type_non_partitioned_columns\n",
        "incrementalKey" : false,
        "incremental" : {
          "expression" : "true"
        }
      },
      "ports" : {
        "inputs" : [ {
          "id" : "ZkQeiKch",
          "slug" : "all_type_non_partitioned_columns"
        } ],
        "outputs" : [ {
          "id" : "fBRpnqfP",
          "slug" : "out"
        } ],
        "isCustomOutputSchema" : false,
        "autoUpdateOnRun" : false
      }
    },
    "-TlF2o1x3V-z8K0Gn0sqq$$NrRkoB5hBMfNT4XOvNAdj" : {
      "id" : "-TlF2o1x3V-z8K0Gn0sqq$$NrRkoB5hBMfNT4XOvNAdj",
      "component" : "Reformat",
      "metadata" : {
        "label" : "all_type_non_partitioned_columns",
        "slug" : "all_type_non_partitioned_columns",
        "x" : 40,
        "y" : -40,
        "phase" : 0,
        "macroDependencies" : [ ],
        "comment" : "Extracts all non-partitioned columns from the 'all_type_non_partitioned' table.",
        "autoUpdateComment" : true
      },
      "properties" : {
        "columnsSelector" : [ "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_tinyint", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_smallint", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_int", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_bigint", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_float", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_double", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_string", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_boolean", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_array", "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB##c_struct" ],
        "expressions" : [ {
          "expression" : {
            "expression" : "c_tinyint"
          },
          "alias" : "c_tinyint"
        }, {
          "expression" : {
            "expression" : "c_smallint"
          },
          "alias" : "c_smallint"
        }, {
          "expression" : {
            "expression" : "c_int"
          },
          "alias" : "c_int"
        }, {
          "expression" : {
            "expression" : "c_bigint"
          },
          "alias" : "c_bigint"
        }, {
          "expression" : {
            "expression" : "c_float"
          },
          "alias" : "c_float"
        }, {
          "expression" : {
            "expression" : "c_double"
          },
          "alias" : "c_double"
        }, {
          "expression" : {
            "expression" : "c_string"
          },
          "alias" : "c_string"
        }, {
          "expression" : {
            "expression" : "c_boolean"
          },
          "alias" : "c_boolean"
        }, {
          "expression" : {
            "expression" : "c_array"
          },
          "alias" : "c_array"
        }, {
          "expression" : {
            "expression" : "c_struct"
          },
          "alias" : "c_struct"
        }, {
          "expression" : {
            "expression" : "monotonically_increasing_id()"
          },
          "alias" : "c_id"
        } ]
      },
      "ports" : {
        "inputs" : [ {
          "id" : "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB",
          "slug" : "in0"
        } ],
        "outputs" : [ {
          "id" : "02Siyvol5i76ve7JKL3RX$$3fAKPIKN5o7Rrz7pd88JZ",
          "slug" : "out"
        } ],
        "isCustomOutputSchema" : false,
        "autoUpdateOnRun" : false
      }
    },
    "ZqrocPnb-zwrEAjnrkZJJ" : {
      "id" : "ZqrocPnb-zwrEAjnrkZJJ",
      "component" : "Source",
      "metadata" : {
        "label" : "all_type_non_partitioned_1",
        "slug" : "all_type_non_partitioned_1",
        "x" : -140,
        "y" : -80,
        "phase" : 0
      },
      "properties" : {
        "table" : {
          "name" : "all_type_non_partitioned",
          "sourceType" : "Source",
          "sourceName" : "hive_metastore.qa_database",
          "alias" : "",
          "additionalProperties" : null
        }
      },
      "ports" : {
        "inputs" : [ ],
        "outputs" : [ {
          "id" : "USuFXsqPN-e9OE_P8Z53B",
          "slug" : "out"
        } ],
        "isCustomOutputSchema" : false,
        "autoUpdateOnRun" : false
      }
    }
  },
  "connections" : [ {
    "id" : "pMbq5pxbIDeWPi0LDHjsX$$eymKLWj61t-04o9NzNmUc",
    "source" : "-TlF2o1x3V-z8K0Gn0sqq$$NrRkoB5hBMfNT4XOvNAdj",
    "sourcePort" : "02Siyvol5i76ve7JKL3RX$$3fAKPIKN5o7Rrz7pd88JZ",
    "target" : "uitesting_replacewhere##wceiJ6rJ",
    "targetPort" : "ZkQeiKch"
  }, {
    "id" : "7yO6p2gFVRVtnqh-RW93w$$LqFznxwvnET4VYKV-m_aj",
    "source" : "ZqrocPnb-zwrEAjnrkZJJ",
    "sourcePort" : "USuFXsqPN-e9OE_P8Z53B",
    "target" : "-TlF2o1x3V-z8K0Gn0sqq$$NrRkoB5hBMfNT4XOvNAdj",
    "targetPort" : "MYPBXHIvvHA4_ovvjtSv3$$OJ5i26WqNWU9leh7a3ETB"
  } ],
  "component" : "Model"
}